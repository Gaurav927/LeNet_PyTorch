{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =64\n",
    "train_dataset = datasets.FashionMNIST(root='./FashionMNIST/',\n",
    "                               train=True,\n",
    "                               transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = datasets.FashionMNIST(root='./FashionMNIST/',\n",
    "                              train=False,\n",
    "                              transform=transforms.ToTensor())\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show an image\n",
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "classes = ('T-shirt/top', 'Trouser','Pullover','Dress', 'Coat','Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle-boot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sneaker Pullover Dress Sandal\n"
     ]
    }
   ],
   "source": [
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:4],nrow=4))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In original paper input size is 32x32 , but we have taken input size as 28x28\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,6,kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6,16,kernel_size=3)        \n",
    "        self.pooling = nn.MaxPool2d(kernel_size=2,stride=2)  # original paper there is average pooling\n",
    "        self.l1 = nn.Linear(400,120)\n",
    "        self.l2 = nn.Linear(120,10)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x = self.pooling(self.conv1(x))\n",
    "        x = self.pooling(self.conv2(x))\n",
    "        \n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.l1(x)\n",
    "        \n",
    "        x = self.l2(x)\n",
    "        \n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet()\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.308614\n",
      "Train Epoch: 0 [6400/60000 (11%)]\tLoss: 1.472702\n",
      "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.875373\n",
      "Train Epoch: 0 [19200/60000 (32%)]\tLoss: 0.610421\n",
      "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.771768\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.679674\n",
      "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.671654\n",
      "Train Epoch: 0 [44800/60000 (75%)]\tLoss: 0.681265\n",
      "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.744454\n",
      "Train Epoch: 0 [57600/60000 (96%)]\tLoss: 0.545676\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.697384\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.613489\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.538601\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.657365\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.743274\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.539485\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.443585\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.525225\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.459159\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.539044\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.529060\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.317664\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.427692\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.539558\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.358731\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.535056\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.524498\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.659880\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.698175\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.437423\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.332522\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.530890\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.595506\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.280584\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.527730\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.453463\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.353964\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.432003\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.376200\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.406140\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.519719\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.432112\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.553604\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.372644\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.234568\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.440488\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.407580\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.402265\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.358386\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.482765\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.396242\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.394137\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.330992\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.507612\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.292584\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.328308\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.282278\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.378177\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.394815\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.386954\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.625236\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.328920\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.175121\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.322020\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.534297\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.262369\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.274045\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.439016\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.302697\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.344746\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.298623\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.270706\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.281644\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.394161\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.434634\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.238476\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.281561\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.616481\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.522570\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.280184\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.420810\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.455410\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.194618\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.387167\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.323083\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.437056\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.480814\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.409851\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.427887\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.440194\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.368624\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.435248\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.261169\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.335970\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.340176\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.246328\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.489809\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.406268\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.405049\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.339117\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):\n",
    "    for i ,(data,target) in enumerate(train_loader):\n",
    "        data,target = Variable(data),Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model.forward(data)\n",
    "        loss = criterion(y_pred,target)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if i % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, i * len(data), len(train_loader.dataset),\n",
    "                100. * i / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0061, Accuracy: 8626/10000 (86%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    output = model.forward(data)\n",
    "    # sum up batch loss\n",
    "    test_loss += criterion(output, target).item()\n",
    "    # get the index of the max\n",
    "    pred = output.data.max(dim=1,keepdim=True)[1]\n",
    "    \n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
